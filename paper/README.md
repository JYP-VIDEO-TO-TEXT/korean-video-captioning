# ë…¼ë¬¸ ì •ë¦¬

ëŒ€í•œë¯¼êµ­ ë°°ê²½ì˜ìƒ ìº¡ì…”ë‹ í”„ë¡œì íŠ¸ì— í•„ìš”í•œ í•µì‹¬ ë…¼ë¬¸ë“¤ì„ ì •ë¦¬í•©ë‹ˆë‹¤.

---

## ğŸ¯ í”„ë¡œì íŠ¸ ëª©í‘œ

> **AI-Hub ë² ì´ìŠ¤ë¼ì¸ METEOR 0.3052 â†’ 0.40+ ë‹¬ì„±**

ì´ë¥¼ ìœ„í•´ Vision-Language Modelì˜ ìµœì‹  ì—°êµ¬ë“¤ì„ ë¶„ì„í•˜ê³  ì ìš©í•©ë‹ˆë‹¤.

---

## ğŸ“Š ì „ì²´ ê¸°ìˆ  ë°œì „ íë¦„

### Vision-Language Model ìƒíƒœê³„

```mermaid
flowchart TB
    subgraph Foundation["ğŸ—ï¸ ê¸°ë°˜ ê¸°ìˆ "]
        direction LR
        ViT[ViT<br/>2020] --> CLIP[CLIP<br/>2021]
        GPT[GPT ê³„ì—´] --> LLaMA[LLaMA<br/>2023]
    end

    subgraph Vision["ğŸ‘ï¸ Vision Encoder ë°œì „"]
        CLIP --> SigLIP[SigLIP<br/>2023<br/>ë‹¤êµ­ì–´+Sigmoid]
        CLIP --> DINO[DINO<br/>2021]
        DINO --> DINOv2[DINOv2<br/>2023<br/>Dense Features]
        DINOv2 --> DINOv3[DINOv3<br/>2024<br/>Gram Anchoring]
    end

    subgraph LLM["ğŸ§  LLM ë°œì „"]
        LLaMA --> Vicuna[Vicuna<br/>2023<br/>ëŒ€í™” íŠ¹í™”]
        LLaMA --> Qwen[Qwen<br/>2023<br/>ë‹¤êµ­ì–´]
        Qwen --> Qwen2[Qwen2<br/>2024<br/>GQA+128K]
        Qwen2 --> Qwen3[Qwen3<br/>2025<br/>MoE+ìµœê³ ì„±ëŠ¥]
    end

    subgraph VLM["ğŸ”— VLM í†µí•©"]
        LLaVA[LLaVA<br/>2023<br/>Visual Instruction]
        LLaVA --> LLaVA_NeXT[LLaVA-NeXT<br/>2024<br/>AnyRes]
        LLaVA_NeXT --> LLaVA_Video[LLaVA-NeXT-Video<br/>2024<br/>ë¹„ë””ì˜¤ íŠ¹í™”]
        LLaVA_NeXT --> Video_LLaVA[Video-LLaVA<br/>2024<br/>í†µí•© í•™ìŠµ]
    end

    CLIP --> LLaVA
    Vicuna --> LLaVA

    subgraph Project["ğŸ¯ ìš°ë¦¬ í”„ë¡œì íŠ¸"]
        Apply[í•œêµ­ì–´ ë¹„ë””ì˜¤ ìº¡ì…”ë‹<br/>METEOR 0.40+ ëª©í‘œ]
    end

    LLaVA_Video ==> Apply
    Qwen3 -.-> Apply
    SigLIP -.-> Apply
    DINOv3 -.-> Apply

    style Apply fill:#ff6b6b,stroke:#c92a2a,color:#fff
    style LLaVA_Video fill:#4dabf7,stroke:#1971c2
    style Qwen3 fill:#69db7c,stroke:#2f9e44
```

---

## ğŸ”§ ìš°ë¦¬ í”„ë¡œì íŠ¸ì˜ ê¸°ìˆ  ìŠ¤íƒ

### í•µì‹¬ ì˜ì¡´ ê´€ê³„

```mermaid
flowchart TB
    subgraph Core["ğŸ“¦ ê¸°ë°˜ ëª¨ë¸"]
        Base[LLaVA-NeXT-Video-7B<br/>Hugging Faceì—ì„œ ì œê³µ]
    end

    subgraph Components["ğŸ§© ì£¼ìš” ì»´í¬ë„ŒíŠ¸"]
        Vision[Vision Encoder<br/>CLIP ViT-L/14<br/>ğŸ“· ì´ë¯¸ì§€â†’í† í°]
        Proj[Projector<br/>Linear Layer<br/>ğŸ”— ê³µê°„ ì—°ê²°]
        LLM[LLM Backbone<br/>Vicuna-7B<br/>ğŸ“ í…ìŠ¤íŠ¸ ìƒì„±]
    end

    subgraph Upgrade["â¬†ï¸ ì—…ê·¸ë ˆì´ë“œ ì˜µì…˜"]
        Vision_Up[SigLIP<br/>ë‹¤êµ­ì–´ ì´í•´ â†‘<br/>â”€â”€â”€â”€â”€â”€â”€â”€â”€<br/>DINOv3<br/>ì„¸ë°€í•œ ë¬˜ì‚¬ â†‘]
        LLM_Up[Qwen3<br/>í•œêµ­ì–´ ì„±ëŠ¥ â†‘<br/>â”€â”€â”€â”€â”€â”€â”€â”€â”€<br/>MoEë¡œ íš¨ìœ¨ â†‘]
    end

    subgraph Training["ğŸ“ í•™ìŠµ ë°©ë²•"]
        QLoRA[QLoRA<br/>4-bit ì–‘ìí™”<br/>ë©”ëª¨ë¦¬ 90% ì ˆì•½]
        Stage[2-Stage Training<br/>1. ì •ë ¬ í•™ìŠµ<br/>2. íƒœìŠ¤í¬ í•™ìŠµ]
    end

    subgraph Deploy["ğŸš€ ë°°í¬ ìµœì í™”"]
        AWQ[AWQ ì–‘ìí™”<br/>ì¶”ë¡  ì†ë„ 3xâ†‘]
        vLLM[vLLM ì„œë¹™<br/>ì²˜ë¦¬ëŸ‰ 4xâ†‘]
    end

    Base --> Vision
    Base --> Proj
    Base --> LLM

    Vision -.->|êµì²´ ê°€ëŠ¥| Vision_Up
    LLM -.->|êµì²´ ê°€ëŠ¥| LLM_Up

    Components --> Training
    Training --> Deploy

    style Base fill:#e7f5ff,stroke:#1971c2
    style QLoRA fill:#fff3bf,stroke:#f59f00
    style vLLM fill:#d3f9d8,stroke:#2f9e44
```

---

## ğŸ“š ì¹´í…Œê³ ë¦¬ë³„ ë…¼ë¬¸ ì •ë¦¬

### 1. [VLM Core](vlm_core/) - Vision-Language Model í•µì‹¬

> ğŸ’¡ **í•µì‹¬ ì§ˆë¬¸**: ì´ë¯¸ì§€/ë¹„ë””ì˜¤ë¥¼ ì–´ë–»ê²Œ ì´í•´í•˜ê³  ì„¤ëª…í•  ê²ƒì¸ê°€?

```mermaid
flowchart LR
    subgraph Evolution["VLM ì§„í™”"]
        A[LLaVA] -->|ê³ í•´ìƒë„| B[LLaVA-NeXT]
        B -->|ë¹„ë””ì˜¤| C[LLaVA-NeXT-Video]
    end
    
    C -->|ìš°ë¦¬ ì„ íƒ| D[í•œêµ­ì–´ ìº¡ì…”ë‹]
    
    style D fill:#ff6b6b,stroke:#c92a2a,color:#fff
```

| ë…¼ë¬¸ | ì—°ë„ | í•µì‹¬ ì•„ì´ë””ì–´ | ìš°ë¦¬ í”„ë¡œì íŠ¸ ê´€ë ¨ì„± |
|------|------|--------------|-------------------|
| [LLaVA](vlm_core/llava.md) | 2023 | GPT-4ë¡œ í•™ìŠµ ë°ì´í„° ìƒì„±, 2-Stage í•™ìŠµ | í•™ìŠµ ì „ëµì˜ ê¸°ì´ˆ |
| [LLaVA-NeXT](vlm_core/llava_next.md) | 2024 | AnyResë¡œ ë‹¤ì–‘í•œ í•´ìƒë„ ì§€ì› | ê³ í•´ìƒë„ ì²˜ë¦¬ ë°©ì‹ ì´í•´ |
| [LLaVA-NeXT-Video](vlm_core/llava_next_video.md) | 2024 | ì´ë¯¸ì§€ë§Œìœ¼ë¡œ í•™ìŠµí•´ë„ ë¹„ë””ì˜¤ ì´í•´ | â­ **ìš°ë¦¬ ê¸°ë³¸ ëª¨ë¸** |
| [Video-LLaVA](vlm_core/video_llava.md) | 2024 | ì´ë¯¸ì§€+ë¹„ë””ì˜¤ ë™ì‹œ í•™ìŠµ | ëŒ€ì•ˆ ëª¨ë¸ |

---

### 2. [Vision Encoders](vision_encoders/) - ë¹„ì „ ì¸ì½”ë”

> ğŸ’¡ **í•µì‹¬ ì§ˆë¬¸**: ì´ë¯¸ì§€ì—ì„œ ì–´ë–¤ íŠ¹ì§•ì„ ì¶”ì¶œí•  ê²ƒì¸ê°€?

```mermaid
flowchart TB
    subgraph Paradigm["í•™ìŠµ íŒ¨ëŸ¬ë‹¤ì„"]
        Sup[Supervised<br/>í…ìŠ¤íŠ¸-ì´ë¯¸ì§€ ìŒ í•„ìš”]
        Self[Self-Supervised<br/>ì´ë¯¸ì§€ë§Œìœ¼ë¡œ í•™ìŠµ]
    end

    subgraph Supervised_Models["Contrastive Learning"]
        CLIP[CLIP<br/>ì˜ì–´ ì¤‘ì‹¬]
        SigLIP[SigLIP<br/>109ê°œ ì–¸ì–´]
    end

    subgraph Self_Models["Self-Distillation"]
        DINOv2[DINOv2<br/>ì¼ë°˜ íŠ¹ì§•]
        DINOv3[DINOv3<br/>Dense íŠ¹ì§•]
    end

    Sup --> CLIP --> SigLIP
    Self --> DINOv2 --> DINOv3

    subgraph Choose["ì„ íƒ ê¸°ì¤€"]
        C1[ë‹¤êµ­ì–´ í•„ìš”?<br/>â†’ SigLIP]
        C2[ì„¸ë°€í•œ ë¬˜ì‚¬?<br/>â†’ DINOv3]
        C3[ë©”ëª¨ë¦¬ ì œì•½?<br/>â†’ CLIP]
    end

    style SigLIP fill:#69db7c,stroke:#2f9e44
    style DINOv3 fill:#4dabf7,stroke:#1971c2
```

| ë…¼ë¬¸ | ì—°ë„ | í•™ìŠµ ë°©ì‹ | ê°•ì  | ì•½ì  |
|------|------|----------|------|------|
| [CLIP](vision_encoders/clip.md) | 2021 | Contrastive | Zero-shot, ì•ˆì •ì  | ì˜ì–´ í¸í–¥, Dense ì•½í•¨ |
| [SigLIP](vision_encoders/siglip.md) | 2023 | Sigmoid CE | ë‹¤êµ­ì–´, í•œêµ­ì–´â†‘ | í† í° ìˆ˜ ì¦ê°€ |
| [DINOv2](vision_encoders/dinov2.md) | 2023 | Self-distill | Dense features | í…ìŠ¤íŠ¸ ì •ë ¬ í•„ìš” |
| [DINOv3](vision_encoders/dinov3.md) | 2024 | Gram Anchor | ìµœê³  í’ˆì§ˆ | âš ï¸ ìŠ¹ì¸ í•„ìš” |

---

### 3. [LLM Backbones](llm_backbones/) - LLM ë°±ë³¸

> ğŸ’¡ **í•µì‹¬ ì§ˆë¬¸**: ì–´ë–¤ ì–¸ì–´ ëª¨ë¸ì´ í•œêµ­ì–´ë¥¼ ì˜ ìƒì„±í•˜ëŠ”ê°€?

```mermaid
flowchart LR
    subgraph Performance["í•œêµ­ì–´ ì„±ëŠ¥ ìˆœìœ„"]
        direction TB
        P1["ğŸ¥‡ Qwen3-14B<br/>72.3%"]
        P2["ğŸ¥ˆ Qwen3-8B<br/>68.5%"]
        P3["ğŸ¥‰ Qwen2-7B<br/>62.1%"]
        P4["4ìœ„ Qwen-7B<br/>52.1%"]
        P5["5ìœ„ Vicuna-7B<br/>38.2%"]
    end

    subgraph Choice["ìš°ë¦¬ ì„ íƒ"]
        C[Vicuna â†’ Qwen3<br/>í•œêµ­ì–´ ì„±ëŠ¥ 2ë°°â†‘]
    end

    P1 --> C
    
    style P1 fill:#ffd43b,stroke:#f59f00
    style C fill:#ff6b6b,stroke:#c92a2a,color:#fff
```

| ë…¼ë¬¸ | ì—°ë„ | íŒŒë¼ë¯¸í„° | í•œêµ­ì–´ MMLU | íŠ¹ì§• |
|------|------|----------|------------|------|
| [LLaMA](llm_backbones/llama.md) | 2023 | 7B-65B | 34.5% | ì˜¤í”ˆì†ŒìŠ¤ ì‹œì‘ |
| [Qwen](llm_backbones/qwen.md) | 2023 | 7B-72B | 52.1% | ë‹¤êµ­ì–´ íŠ¹í™” |
| [Qwen2](llm_backbones/qwen2.md) | 2024 | 7B-72B | 62.1% | GQA, 128K ì»¨í…ìŠ¤íŠ¸ |
| [Qwen3](llm_backbones/qwen3.md) | 2025 | 0.6B-235B | **72.3%** | â­ MoE, ìµœê³  ì„±ëŠ¥ |

---

### 4. [Training Methods](training_methods/) - í•™ìŠµ ê¸°ë²•

> ğŸ’¡ **í•µì‹¬ ì§ˆë¬¸**: ì œí•œëœ GPUì—ì„œ ì–´ë–»ê²Œ íš¨ìœ¨ì ìœ¼ë¡œ í•™ìŠµí•  ê²ƒì¸ê°€?

```mermaid
flowchart TB
    subgraph Memory["GPU ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰"]
        Full[Full Fine-tuning<br/>112GB ğŸ’€]
        LoRA[LoRA<br/>56GB ğŸ˜“]
        QLoRA[QLoRA<br/>6GB âœ¨]
    end

    Full -->|íŒŒë¼ë¯¸í„° íš¨ìœ¨í™”| LoRA
    LoRA -->|4-bit ì–‘ìí™”| QLoRA

    subgraph Result["ê²°ê³¼"]
        R[T4 16GBì—ì„œ<br/>7B ëª¨ë¸ í•™ìŠµ ê°€ëŠ¥!]
    end

    QLoRA --> R

    style QLoRA fill:#69db7c,stroke:#2f9e44
    style R fill:#ffd43b,stroke:#f59f00
```

| ë…¼ë¬¸ | ì—°ë„ | ë©”ëª¨ë¦¬ ì ˆì•½ | í’ˆì§ˆ | ìš°ë¦¬ ì ìš© |
|------|------|-----------|------|----------|
| [LoRA](training_methods/lora.md) | 2021 | ~50% | ì¢‹ìŒ | A100+ |
| [QLoRA](training_methods/qlora.md) | 2023 | ~90% | ì¢‹ìŒ | â­ T4/L4 í•„ìˆ˜ |
| [DoRA](training_methods/dora.md) | 2024 | ~50% | ë” ì¢‹ìŒ | ì„ íƒì  |
| [2-Stage](training_methods/llava_2stage.md) | 2023 | - | - | â­ í•™ìŠµ ì „ëµ |

---

### 5. [Inference Optimization](inference_opt/) - ì¶”ë¡  ìµœì í™”

> ğŸ’¡ **í•µì‹¬ ì§ˆë¬¸**: í•™ìŠµëœ ëª¨ë¸ì„ ì–´ë–»ê²Œ ë¹ ë¥´ê²Œ ì„œë¹™í•  ê²ƒì¸ê°€?

```mermaid
flowchart LR
    subgraph Speed["ì†ë„ í–¥ìƒ ì¡°í•©"]
        Base[ê¸°ë³¸<br/>1x] -->|ì–‘ìí™”| AWQ[+AWQ<br/>3x]
        AWQ -->|ì„œë¹™| vLLM[+vLLM<br/>6x]
        vLLM -->|ì¶”ë¡ | Spec[+SpecDec<br/>8x+]
    end

    subgraph GPU["GPUë³„ ì ìš©"]
        T4[T4: ê¸°ë³¸ë§Œ]
        L4[L4: AWQ]
        A100[A100: AWQ+vLLM]
        H100[H100: ì „ë¶€ ì ìš©]
    end

    style Spec fill:#69db7c,stroke:#2f9e44
    style H100 fill:#ffd43b,stroke:#f59f00
```

| ë…¼ë¬¸ | ì—°ë„ | ì†ë„ í–¥ìƒ | í•µì‹¬ ê¸°ìˆ  | ì ìš© ì‹œì  |
|------|------|----------|----------|----------|
| [GPTQ](inference_opt/gptq.md) | 2022 | 2-3x | Post-training ì–‘ìí™” | ë°°í¬ ì‹œ |
| [AWQ](inference_opt/awq.md) | 2023 | 3-4x | Activation-aware | â­ A100+ |
| [vLLM](inference_opt/vllm.md) | 2023 | 2-4x | PagedAttention | â­ A100+ |
| [Speculative](inference_opt/speculative_decoding.md) | 2023 | 2-3x | Draft-Verify | H100 |

---

## ğŸ—ºï¸ í”„ë¡œì íŠ¸ ë¡œë“œë§µ

```mermaid
timeline
    title í”„ë¡œì íŠ¸ ì§„í–‰ ë‹¨ê³„
    
    section Phase 1
        ê¸°ë³¸ êµ¬ì¶• : LLaVA-NeXT-Video-7B ì„¤ì •
                 : QLoRA í•™ìŠµ í™˜ê²½ êµ¬ì„±
                 : AI-Hub ë°ì´í„° ì „ì²˜ë¦¬
    
    section Phase 2
        LLM ì—…ê·¸ë ˆì´ë“œ : Vicuna â†’ Qwen3 êµì²´
                      : í•œêµ­ì–´ ì„±ëŠ¥ í–¥ìƒ ê²€ì¦
                      : METEOR 0.35 ëª©í‘œ
    
    section Phase 3
        Vision ì—…ê·¸ë ˆì´ë“œ : CLIP â†’ SigLIP ë˜ëŠ” DINOv3
                         : Stage 1 ì¬í•™ìŠµ
                         : METEOR 0.40 ëª©í‘œ
    
    section Phase 4
        ë°°í¬ ìµœì í™” : AWQ ì–‘ìí™”
                   : vLLM ì„œë¹™
                   : API ì„œë²„ êµ¬ì¶•
```

---

## ğŸ’» GPUë³„ ê¶Œì¥ êµ¬ì„±

```mermaid
flowchart TB
    subgraph T4["ğŸŸ¡ T4 (16GB)"]
        T4_V[Vision: CLIP]
        T4_L[LLM: Qwen3-4B]
        T4_T[í•™ìŠµ: QLoRA r=8]
        T4_I[ì¶”ë¡ : ê¸°ë³¸]
    end

    subgraph L4["ğŸŸ¢ L4 (24GB)"]
        L4_V[Vision: SigLIP]
        L4_L[LLM: Qwen3-8B]
        L4_T[í•™ìŠµ: QLoRA r=16]
        L4_I[ì¶”ë¡ : AWQ]
    end

    subgraph A100["ğŸ”µ A100 (40GB)"]
        A100_V[Vision: DINOv3-L]
        A100_L[LLM: Qwen3-14B]
        A100_T[í•™ìŠµ: LoRA r=32]
        A100_I[ì¶”ë¡ : AWQ+vLLM]
    end

    subgraph H100["ğŸŸ£ H100 (80GB)"]
        H100_V[Vision: DINOv3-H]
        H100_L[LLM: Qwen3-32B]
        H100_T[í•™ìŠµ: LoRA r=64]
        H100_I[ì¶”ë¡ : ì „ë¶€]
    end

    style T4 fill:#fff3bf
    style L4 fill:#d3f9d8
    style A100 fill:#d0ebff
    style H100 fill:#e5dbff
```

---

## ğŸ“– ì¶”ì²œ í•™ìŠµ ìˆœì„œ

### ğŸŒ± ì…ë¬¸ì

```mermaid
flowchart LR
    A[1. LLaVA<br/>VLM ê¸°ë³¸ ê°œë…] --> B[2. LoRA<br/>íš¨ìœ¨ì  í•™ìŠµ]
    B --> C[3. QLoRA<br/>ì‹¤ì œ ì ìš©]
    
    style A fill:#e7f5ff
    style B fill:#fff3bf
    style C fill:#d3f9d8
```

### ğŸŒ³ ì‹¬í™” í•™ìŠµ

```mermaid
flowchart TB
    subgraph Vision_Path["Vision ì‹¬í™”"]
        V1[CLIP] --> V2[SigLIP] --> V3[DINOv3]
    end
    
    subgraph LLM_Path["LLM ì‹¬í™”"]
        L1[LLaMA] --> L2[Qwen] --> L3[Qwen3]
    end
    
    subgraph Opt_Path["ìµœì í™” ì‹¬í™”"]
        O1[vLLM] --> O2[AWQ] --> O3[SpecDec]
    end
```

### ğŸ¯ í”„ë¡œì íŠ¸ ì§ì ‘ ê´€ë ¨

1. **[LLaVA-NeXT-Video](vlm_core/llava_next_video.md)** - ìš°ë¦¬ ê¸°ë³¸ ëª¨ë¸
2. **[Qwen3](llm_backbones/qwen3.md)** - LLM ì—…ê·¸ë ˆì´ë“œ ëŒ€ìƒ
3. **[QLoRA](training_methods/qlora.md)** - í•™ìŠµ í•„ìˆ˜ ê¸°ë²•
4. **[2-Stage Training](training_methods/llava_2stage.md)** - í•™ìŠµ ì „ëµ
